{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alexa Andrews and Jeffrey Mulderink  \n",
    "#### Group name: aa_jm_knn   \n",
    "#### Project title: Improved kNN classifier\n",
    "\n",
    "\n",
    "Our data set was looking to predict whether a person would default on their credit card payment based\n",
    "Since our table has around 30 thousand instances and kNN is rather slow, we used a random subset of our data in our tests.  \n",
    "We thought we should remove the first column of our table, which was ID, because the order these instances happen to be in shouldn't be of relevance to whether they will make their next payment, and it was not included on the list of attributes for the dataset. Initially we had ID and oddly enough removing it led to lower recall, precision, and F-measure for different k values. Without removing ID, it was often amongst the top attributes in the top subset. From visual inspection of our data, it did not appear that the class label was sorted in any way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "\n",
    "header, table = utils.open_csv_with_header(\"default_of_credit_card_clients.csv\")\n",
    "\n",
    "np.random.shuffle(table)\n",
    "table = table[:200]\n",
    "\n",
    "header = header[1:]\n",
    "table = utils.remove_column(table, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_attribute_subset(table, header, num_values):\n",
    "    '''\n",
    "        Returns a copy table with a random columns removed\n",
    "        Param table: A table to remove attributes from\n",
    "        Param header: The attribute names\n",
    "        Param num_values: The number of attributes to keep\n",
    "        Returns: A tuple with the first item being the table with num_values random attibutes\n",
    "                and the second item a list of the names of the attributes it chose\n",
    "    '''\n",
    "    smaller_table = copy.deepcopy(table)\n",
    "    num_attributes = len(smaller_table[0])\n",
    "    indices_to_remove = random.sample(range(0, num_attributes-1), num_attributes-num_values) \n",
    "    indices_to_remove.sort(reverse=True)\n",
    "    for c in indices_to_remove:\n",
    "        for r, _ in enumerate(smaller_table):\n",
    "            del smaller_table[r][c] \n",
    "        \n",
    "    attributes_kept = [header[i] for i in range(num_attributes) if i not in indices_to_remove]\n",
    "        \n",
    "    return smaller_table, attributes_kept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more class 0 than class 1. This zero_R_classifier tests the accuracy (other metrics don't make sense with TP=0) of just predicting 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "def zero_r(table):\n",
    "    '''\n",
    "        A zero rules classifier which returns the most common class\n",
    "        Param table:  A table with classifications of instances in the last row\n",
    "        Returns: The most frequent class\n",
    "    '''\n",
    "    classes, counts = utils.get_frequencies(table, -1)\n",
    "    combo = [(counts[i], classes[i]) for i in range(len(classes))]\n",
    "    combo.sort(reverse=True)\n",
    "    return combo[0][1]\n",
    "\n",
    "\n",
    "\n",
    "def zero_R_classifier(table, measurement='a'):\n",
    "    folds = utils.get_stratified_folds(table)\n",
    "    prediction = zero_r(table)\n",
    "\n",
    "    predictions, actuals = [], [] \n",
    "    for i, fold in enumerate(folds):\n",
    "        train = [instance for fold in folds[:i] for instance in fold] + [instance for fold in folds[i+1:] for instance in fold]\n",
    "        test, train = utils.normalize_attributes(fold, train)\n",
    "        for test_instance in test:\n",
    "            predictions.append(prediction)\n",
    "            actuals.append(test_instance[-1])\n",
    "\n",
    "\n",
    "    correct = [predictions[i] == actuals[i] for i in range(len(predictions))]\n",
    "    return correct.count(True) / len(correct)\n",
    "\n",
    "\n",
    "print(zero_R_classifier(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following cell tests how different k values impact the performace of a kNN classifier. We were surprised by how large K was for optimal results. Before removing ID, these forms of classifier evaluation all tended to be highest in the upper 60 to 100 range, after which they would drop off. After removing ID, around 100 was best for accuracy and recall, but precision and f-measure were much higher, so much so as to be basically using the majority from all training instances. At this point, we created the zero-R classifier above which showed that these Ks were not achieving the same accuracy as simply guessing the majority class, 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing at k=91\n",
      "testing at k=97\n",
      "testing at k=103\n",
      "testing at k=109\n",
      "testing at k=115\n",
      "testing at k=121\n",
      "testing at k=127\n",
      "testing at k=133\n",
      "testing at k=139\n",
      "testing at k=145\n",
      "testing at k=151\n",
      "testing at k=157\n",
      "testing at k=163\n",
      "testing at k=169\n",
      "testing at k=175\n",
      "testing at k=181\n",
      "testing at k=187\n",
      "testing at k=193\n",
      "testing at k=199\n",
      "Accuracies for variable k\n",
      " [(0.715, 91), (0.715, 97), (0.715, 103), (0.715, 109), (0.68, 115), (0.68, 121), (0.645, 127), (0.525, 133), (0.515, 139), (0.51, 145), (0.51, 151), (0.51, 157), (0.47, 163), (0.465, 169), (0.465, 175), (0.465, 181), (0.465, 187), (0.465, 193), (0.465, 199)]\n",
      "sorted [(0.715, 109), (0.715, 103), (0.715, 97), (0.715, 91), (0.68, 121), (0.68, 115), (0.645, 127), (0.525, 133), (0.515, 139), (0.51, 157), (0.51, 151), (0.51, 145), (0.47, 163), (0.465, 199), (0.465, 193), (0.465, 187), (0.465, 181), (0.465, 175), (0.465, 169)]\n",
      "testing at k=91\n",
      "testing at k=97\n",
      "testing at k=103\n",
      "testing at k=109\n",
      "testing at k=115\n",
      "testing at k=121\n",
      "testing at k=127\n",
      "testing at k=133\n",
      "testing at k=139\n",
      "testing at k=145\n",
      "testing at k=151\n",
      "testing at k=157\n",
      "testing at k=163\n",
      "testing at k=169\n",
      "testing at k=175\n",
      "testing at k=181\n",
      "testing at k=187\n",
      "testing at k=193\n",
      "testing at k=199\n",
      "sorted [(0.29411764705882354, 109), (0.29411764705882354, 103), (0.29411764705882354, 97), (0.29411764705882354, 91), (0.26666666666666666, 121), (0.26666666666666666, 115), (0.23170731707317074, 139), (0.23076923076923078, 133), (0.23076923076923078, 127), (0.2222222222222222, 157), (0.2222222222222222, 151), (0.2222222222222222, 145), (0.19767441860465115, 163), (0.19047619047619047, 199), (0.19047619047619047, 193), (0.19047619047619047, 187), (0.19047619047619047, 181), (0.19047619047619047, 175), (0.19047619047619047, 169)]\n",
      "testing at k=91\n",
      "testing at k=97\n",
      "testing at k=103\n",
      "testing at k=109\n",
      "testing at k=115\n",
      "testing at k=121\n",
      "testing at k=127\n",
      "testing at k=133\n",
      "testing at k=139\n",
      "testing at k=145\n",
      "testing at k=151\n",
      "testing at k=157\n",
      "testing at k=163\n",
      "testing at k=169\n",
      "testing at k=175\n",
      "testing at k=181\n",
      "testing at k=187\n",
      "testing at k=193\n",
      "testing at k=199\n",
      "sorted [(0.41304347826086957, 139), (0.391304347826087, 157), (0.391304347826087, 151), (0.391304347826087, 145), (0.391304347826087, 133), (0.3695652173913043, 163), (0.34782608695652173, 199), (0.34782608695652173, 193), (0.34782608695652173, 187), (0.34782608695652173, 181), (0.34782608695652173, 175), (0.34782608695652173, 169), (0.1956521739130435, 127), (0.17391304347826086, 121), (0.17391304347826086, 115), (0.10869565217391304, 109), (0.10869565217391304, 103), (0.10869565217391304, 97), (0.10869565217391304, 91)]\n",
      "testing at k=91\n",
      "testing at k=97\n",
      "testing at k=103\n",
      "testing at k=109\n",
      "testing at k=115\n",
      "testing at k=121\n",
      "testing at k=127\n",
      "testing at k=133\n",
      "testing at k=139\n",
      "testing at k=145\n",
      "testing at k=151\n",
      "testing at k=157\n",
      "testing at k=163\n",
      "testing at k=169\n",
      "testing at k=175\n",
      "testing at k=181\n",
      "testing at k=187\n",
      "testing at k=193\n",
      "testing at k=199\n",
      "sorted [(0.296875, 139), (0.2903225806451613, 133), (0.2834645669291338, 157), (0.2834645669291338, 151), (0.2834645669291338, 145), (0.25757575757575757, 163), (0.24615384615384614, 199), (0.24615384615384614, 193), (0.24615384615384614, 187), (0.24615384615384614, 181), (0.24615384615384614, 175), (0.24615384615384614, 169), (0.21176470588235294, 127), (0.2105263157894737, 121), (0.2105263157894737, 115), (0.15873015873015875, 109), (0.15873015873015875, 103), (0.15873015873015875, 97), (0.15873015873015875, 91)]\n"
     ]
    }
   ],
   "source": [
    "def create_kNN_classifier_vary_k(table, start_k=9, end_k=99, step=6, measurement='a'):\n",
    "    '''\n",
    "        This function uses stratified cross fold validation to test different k values for a table.\n",
    "        It can return measurements of accuracy ('a'), recall('r'), precision('p'), or F-measure('f')\n",
    "        Param table: A table to test kNN on\n",
    "        Param start_k: The minimum k value to test.\n",
    "        Param end_k: The maximum k value to test\n",
    "        Param step: The step between k values tested. \n",
    "        Param measurement: The measurement type to return \n",
    "                            accuracy ('a'), recall('r'), precision('p'), or F-measure('f')\n",
    "        Returns: A list of tuples (measurement_value, k)\n",
    "    '''\n",
    "    folds = utils.get_stratified_folds(table)\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    for k in range(start_k, end_k, step):\n",
    "        print(\"testing at k=%d\" % k)\n",
    "        predictions, actuals = [], [] \n",
    "        for i, fold in enumerate(folds):\n",
    "            train = [instance for fold in folds[:i] for instance in fold] + [instance for fold in folds[i+1:] for instance in fold]\n",
    "            test, train = utils.normalize_attributes(fold, train)\n",
    "            utils.remove_column(train, -1) # remove the class column before prediction\n",
    "            for test_instance in test:\n",
    "                predictions.append(utils.make_kNN_prediction(test_instance[:-1], train, k))\n",
    "                actuals.append(test_instance[-1])\n",
    "        \n",
    "        if measurement == 'a':\n",
    "            correct = [predictions[i] == actuals[i] for i in range(len(predictions))]\n",
    "            results.append((correct.count(True) / len(correct), k))\n",
    "        else:\n",
    "            true_positives = [predictions[i]==1 and actuals[i]==1 for i in range(len(predictions))]\n",
    "            if measurement == 'r':\n",
    "                predicted_positives = predictions.count(1)\n",
    "                results.append((true_positives.count(True)/predicted_positives,k))\n",
    "            elif measurement == 'p':\n",
    "                actual_positives = actuals.count(1)\n",
    "                results.append((true_positives.count(True)/actual_positives,k))\n",
    "            elif measurement == 'f':\n",
    "                recall = true_positives.count(True) / predictions.count(1)\n",
    "                precision = true_positives.count(True) / actuals.count(1)\n",
    "                results.append((2*precision*recall/(precision+recall),k))\n",
    "            else:\n",
    "                print(\"error - invalid measurement\", measurement)\n",
    "                break\n",
    "    return results\n",
    "\n",
    "\n",
    "accuracies_k = create_kNN_classifier_vary_k(table, start_k=91, end_k=200)\n",
    "print(\"Accuracies for variable k\\n\", accuracies_k)\n",
    "accuracies_k.sort(reverse=True)\n",
    "print(\"sorted\", accuracies_k)\n",
    "\n",
    "# recalls_k = create_kNN_classifier_vary_k(table, 91, 110, measurement='r')\n",
    "# # print(\"Recall values for variable k\\n\", recalls_k)\n",
    "# recalls_k.sort(reverse=True)\n",
    "# print(\"sorted\", recalls_k)\n",
    "\n",
    "# precisions_k = create_kNN_classifier_vary_k(table, 91, 110, measurement='p')\n",
    "# # print(\"Precision values for variable k\\n\", precisions_k)\n",
    "# precisions_k.sort(reverse=True)\n",
    "# print(\"sorted\", precisions_k)\n",
    "\n",
    "# f_measures_k = create_kNN_classifier_vary_k(table, 91, 110, measurement='f')\n",
    "# # print(\"F-measure values for variable k\\n\", f_measures_k)\n",
    "# f_measures_k.sort(reverse=True)\n",
    "# print(\"sorted\", f_measures_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following classifier uses the best K determined by the previous step and varies which attributes it uses for prediction by taking random attribute subsets of size, default 10, which is passed as a parameter. It does this multiple times and evaluates them using either accuracy, recall, precision, or F-measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing random attribute set 1 of 30\n",
      "testing random attribute set 2 of 30\n",
      "testing random attribute set 3 of 30\n",
      "testing random attribute set 4 of 30\n",
      "testing random attribute set 5 of 30\n",
      "testing random attribute set 6 of 30\n",
      "testing random attribute set 7 of 30\n",
      "testing random attribute set 8 of 30\n",
      "testing random attribute set 9 of 30\n",
      "testing random attribute set 10 of 30\n",
      "testing random attribute set 11 of 30\n",
      "testing random attribute set 12 of 30\n",
      "testing random attribute set 13 of 30\n",
      "testing random attribute set 14 of 30\n",
      "testing random attribute set 15 of 30\n",
      "testing random attribute set 16 of 30\n",
      "testing random attribute set 17 of 30\n",
      "testing random attribute set 18 of 30\n",
      "testing random attribute set 19 of 30\n",
      "testing random attribute set 20 of 30\n",
      "testing random attribute set 21 of 30\n",
      "testing random attribute set 22 of 30\n",
      "testing random attribute set 23 of 30\n",
      "testing random attribute set 24 of 30\n",
      "testing random attribute set 25 of 30\n",
      "testing random attribute set 26 of 30\n",
      "testing random attribute set 27 of 30\n",
      "testing random attribute set 28 of 30\n",
      "testing random attribute set 29 of 30\n",
      "testing random attribute set 30 of 30\n",
      "\n",
      "Best 5 accuracies for variable attribute subset\n",
      " [(0.77, ['PAY_0', 'PAY_2', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT5', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default payment next month']), (0.76, ['SEX', 'PAY_0', 'PAY_6', 'BILL_AMT2', 'BILL_AMT5', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'default payment next month']), (0.76, ['LIMIT_BAL', 'AGE', 'PAY_4', 'PAY_6', 'BILL_AMT2', 'BILL_AMT4', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT6', 'default payment next month']), (0.76, ['ID', 'AGE', 'PAY_2', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT4', 'BILL_AMT5', 'PAY_AMT4', 'default payment next month']), (0.755, ['LIMIT_BAL', 'EDUCATION', 'PAY_4', 'PAY_6', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'PAY_AMT5', 'default payment next month'])]\n",
      "[6, 7, 11, 12, 13, 16, 21, 22, 23, 24]\n",
      "testing random attribute set 1 of 30\n",
      "testing random attribute set 2 of 30\n",
      "testing random attribute set 3 of 30\n",
      "testing random attribute set 4 of 30\n",
      "testing random attribute set 5 of 30\n",
      "testing random attribute set 6 of 30\n",
      "testing random attribute set 7 of 30\n",
      "testing random attribute set 8 of 30\n",
      "testing random attribute set 9 of 30\n",
      "testing random attribute set 10 of 30\n",
      "testing random attribute set 11 of 30\n",
      "testing random attribute set 12 of 30\n",
      "testing random attribute set 13 of 30\n",
      "testing random attribute set 14 of 30\n",
      "testing random attribute set 15 of 30\n",
      "testing random attribute set 16 of 30\n",
      "testing random attribute set 17 of 30\n",
      "testing random attribute set 18 of 30\n",
      "testing random attribute set 19 of 30\n",
      "testing random attribute set 20 of 30\n",
      "testing random attribute set 21 of 30\n",
      "testing random attribute set 22 of 30\n",
      "testing random attribute set 23 of 30\n",
      "testing random attribute set 24 of 30\n",
      "testing random attribute set 25 of 30\n",
      "testing random attribute set 26 of 30\n",
      "testing random attribute set 27 of 30\n",
      "testing random attribute set 28 of 30\n",
      "testing random attribute set 29 of 30\n",
      "testing random attribute set 30 of 30\n",
      "\n",
      "Best 5 recall values for variable attribute subset\n",
      " [(0.6, ['MARRIAGE', 'AGE', 'PAY_0', 'PAY_4', 'PAY_6', 'BILL_AMT1', 'BILL_AMT6', 'PAY_AMT2', 'PAY_AMT6', 'default payment next month']), (0.5555555555555556, ['MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_6', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT2', 'default payment next month']), (0.5, ['SEX', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'BILL_AMT2', 'BILL_AMT4', 'BILL_AMT6', 'PAY_AMT5', 'default payment next month']), (0.5, ['ID', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT5', 'default payment next month']), (0.5, ['EDUCATION', 'AGE', 'PAY_2', 'PAY_3', 'PAY_6', 'BILL_AMT3', 'BILL_AMT4', 'PAY_AMT3', 'PAY_AMT6', 'default payment next month'])]\n",
      "[4, 5, 6, 9, 11, 12, 17, 19, 23, 24]\n",
      "testing random attribute set 1 of 30\n",
      "testing random attribute set 2 of 30\n",
      "testing random attribute set 3 of 30\n",
      "testing random attribute set 4 of 30\n",
      "testing random attribute set 5 of 30\n",
      "testing random attribute set 6 of 30\n",
      "testing random attribute set 7 of 30\n",
      "testing random attribute set 8 of 30\n",
      "testing random attribute set 9 of 30\n",
      "testing random attribute set 10 of 30\n",
      "testing random attribute set 11 of 30\n",
      "testing random attribute set 12 of 30\n",
      "testing random attribute set 13 of 30\n",
      "testing random attribute set 14 of 30\n",
      "testing random attribute set 15 of 30\n",
      "testing random attribute set 16 of 30\n",
      "testing random attribute set 17 of 30\n",
      "testing random attribute set 18 of 30\n",
      "testing random attribute set 19 of 30\n",
      "testing random attribute set 20 of 30\n",
      "testing random attribute set 21 of 30\n",
      "testing random attribute set 22 of 30\n",
      "testing random attribute set 23 of 30\n",
      "testing random attribute set 24 of 30\n",
      "testing random attribute set 25 of 30\n",
      "testing random attribute set 26 of 30\n",
      "testing random attribute set 27 of 30\n",
      "testing random attribute set 28 of 30\n",
      "testing random attribute set 29 of 30\n",
      "testing random attribute set 30 of 30\n",
      "\n",
      "Best 5 precision values for variable attribute subset\n",
      " [(0.5, ['ID', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_4', 'PAY_6', 'BILL_AMT3', 'BILL_AMT5', 'default payment next month']), (0.45454545454545453, ['LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_6', 'BILL_AMT2', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT5', 'PAY_AMT6', 'default payment next month']), (0.4444444444444444, ['PAY_2', 'PAY_6', 'BILL_AMT2', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT5', 'default payment next month']), (0.42857142857142855, ['LIMIT_BAL', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_6', 'BILL_AMT3', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT4', 'default payment next month']), (0.4, ['LIMIT_BAL', 'EDUCATION', 'AGE', 'PAY_4', 'PAY_6', 'BILL_AMT3', 'BILL_AMT5', 'PAY_AMT1', 'PAY_AMT2', 'default payment next month'])]\n",
      "[0, 4, 5, 6, 7, 9, 11, 14, 16, 24]\n",
      "testing random attribute set 1 of 30\n",
      "testing random attribute set 2 of 30\n",
      "testing random attribute set 3 of 30\n",
      "testing random attribute set 4 of 30\n",
      "testing random attribute set 5 of 30\n",
      "testing random attribute set 6 of 30\n",
      "testing random attribute set 7 of 30\n",
      "testing random attribute set 8 of 30\n",
      "testing random attribute set 9 of 30\n",
      "testing random attribute set 10 of 30\n",
      "testing random attribute set 11 of 30\n",
      "testing random attribute set 12 of 30\n",
      "testing random attribute set 13 of 30\n",
      "testing random attribute set 14 of 30\n",
      "testing random attribute set 15 of 30\n",
      "testing random attribute set 16 of 30\n",
      "testing random attribute set 17 of 30\n",
      "testing random attribute set 18 of 30\n",
      "testing random attribute set 19 of 30\n",
      "testing random attribute set 20 of 30\n",
      "testing random attribute set 21 of 30\n",
      "testing random attribute set 22 of 30\n",
      "testing random attribute set 23 of 30\n",
      "testing random attribute set 24 of 30\n",
      "testing random attribute set 25 of 30\n",
      "testing random attribute set 26 of 30\n",
      "testing random attribute set 27 of 30\n",
      "testing random attribute set 28 of 30\n",
      "testing random attribute set 29 of 30\n",
      "testing random attribute set 30 of 30\n",
      "\n",
      "Best 5 precision values for variable attribute subset\n",
      " [(0.375, ['PAY_0', 'PAY_3', 'PAY_5', 'PAY_6', 'BILL_AMT2', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT6', 'default payment next month']), (0.375, ['ID', 'MARRIAGE', 'PAY_3', 'PAY_5', 'PAY_6', 'BILL_AMT3', 'BILL_AMT6', 'PAY_AMT3', 'PAY_AMT6', 'default payment next month']), (0.375, ['ID', 'LIMIT_BAL', 'EDUCATION', 'PAY_0', 'PAY_3', 'BILL_AMT3', 'BILL_AMT4', 'PAY_AMT3', 'PAY_AMT6', 'default payment next month']), (0.36363636363636365, ['MARRIAGE', 'AGE', 'PAY_0', 'PAY_3', 'PAY_4', 'BILL_AMT4', 'BILL_AMT5', 'PAY_AMT2', 'PAY_AMT4', 'default payment next month']), (0.35294117647058826, ['LIMIT_BAL', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT5', 'default payment next month'])]\n",
      "[6, 8, 10, 11, 13, 17, 18, 19, 23, 24]\n"
     ]
    }
   ],
   "source": [
    "def create_kNN_classifier_vary_attributes(table, header, k, iterations=20, F=10, measurement='a'):\n",
    "    '''\n",
    "        Param table: The table used to test different attributes from\n",
    "        Param k: number of nearest neighbors\n",
    "        Param iterations: number of random subsets of attributes tested\n",
    "        Param F: number of attributes per subset\n",
    "        Param measurement: The measurement type to return \n",
    "                            accuracy ('a'), recall('r'), precision('p'), or F-measure('f')\n",
    "    '''\n",
    "    \n",
    "    results = []\n",
    "    for i in range(iterations):\n",
    "        print(\"testing random attribute set\", i+1, \"of\", iterations)\n",
    "        current_table, current_attribs = get_random_attribute_subset(table, header, F)\n",
    "        folds = utils.get_stratified_folds(current_table)\n",
    "        predictions, actuals = [], []\n",
    "        for i, fold in enumerate(folds):\n",
    "            train = [instance for fold in folds[:i] for instance in fold] + [instance for fold in folds[i+1:] for instance in fold]\n",
    "            test, train = utils.normalize_attributes(fold, train)\n",
    "            utils.remove_column(train, -1) # remove the class column before prediction\n",
    "            for test_instance in test:\n",
    "                predictions.append(utils.make_kNN_prediction(test_instance[:-1], train, k))\n",
    "                actuals.append(test_instance[-1])\n",
    "        if measurement == 'a':\n",
    "            correct = [predictions[i] == actuals[i] for i in range(len(predictions))]\n",
    "            results.append((correct.count(True) / len(correct), current_attribs))\n",
    "        else:\n",
    "            true_positives = [predictions[i]==1 and actuals[i]==1 for i in range(len(predictions))]\n",
    "            if measurement == 'r':\n",
    "                predicted_positives = predictions.count(1)\n",
    "                results.append((true_positives.count(True)/predicted_positives, current_attribs))\n",
    "            elif measurement == 'p':\n",
    "                actual_positives = actuals.count(1)\n",
    "                results.append((true_positives.count(True)/actual_positives, current_attribs))\n",
    "            elif measurement == 'f':\n",
    "                recall = true_positives.count(True) / predictions.count(1)\n",
    "                precision = true_positives.count(True) / actuals.count(1)\n",
    "                results.append((2*precision*recall/(precision+recall), current_attribs))\n",
    "    \n",
    "    return results\n",
    "\n",
    "accuracies_a = create_kNN_classifier_vary_attributes(table, header, accuracies_k[0][1], 30)\n",
    "accuracies_a.sort(reverse=True)\n",
    "print(\"\\nBest 5 accuracies for variable attribute subset\\n\", accuracies_a[:5])\n",
    "best_feature_set_indices = [header.index(x) for x in accuracies_a[0][1]]\n",
    "print(best_feature_set_indices)\n",
    "\n",
    "\n",
    "# recalls_a = create_kNN_classifier_vary_attributes(table, header, recalls_k[0][1], 30, measurement='r')\n",
    "# recalls_a.sort(reverse=True)\n",
    "# print(\"\\nBest 5 recall values for variable attribute subset\\n\", recalls_a[:5])\n",
    "# best_feature_set_indices = [header.index(x) for x in recalls_a[0][1]]\n",
    "# print(best_feature_set_indices)\n",
    "\n",
    "# precisions_a = create_kNN_classifier_vary_attributes(table, header, precisions_k[0][1], 30, measurement='r')\n",
    "# precisions_a.sort(reverse=True)\n",
    "# print(\"\\nBest 5 precision values for variable attribute subset\\n\", precisions_a[:5])\n",
    "# best_feature_set_indices = [header.index(x) for x in precisions_a[0][1]]\n",
    "# print(best_feature_set_indices)\n",
    "\n",
    "# f_measures_a = create_kNN_classifier_vary_attributes(table, header, f_measures_k[0][1], 30, measurement='r')\n",
    "# f_measures_a.sort(reverse=True)\n",
    "# print(\"\\nBest 5 precision values for variable attribute subset\\n\", f_measures_a[:5])\n",
    "# best_feature_set_indices = [header.index(x) for x in f_measures_a[0][1]]\n",
    "# print(best_feature_set_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_of_table(table, attributes):\n",
    "    smaller_table = copy.deepcopy(table)\n",
    "    num_attributes = len(smaller_table[0])\n",
    "    indices_to_remove = [i for i in range(num_attributes) if i not in attributes]\n",
    "    indices_to_remove.sort(reverse=True)\n",
    "    for c in indices_to_remove:\n",
    "        for r, _ in enumerate(smaller_table):\n",
    "            del smaller_table[r][c] \n",
    "        \n",
    "    return smaller_table\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kNN_classifier_vary_weights(table, attributes, k): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
